import streamlit as st
import requests
import time
from bs4 import BeautifulSoup
import pandas as pd
from datetime import datetime
import os
import pymysql
import re

# ì €ì¥ ê²½ë¡œ ì„¤ì •
save_dir = "1st_project"
os.makedirs(save_dir, exist_ok=True)

# ìˆ«ì ì¶”ì¶œ ìœ í‹¸ í•¨ìˆ˜
def extract_number(text):
    if not text:
        return None
    match = re.search(r'\d+', text.replace(',', ''))
    return int(match.group()) if match else None

# í¬ë¡¤ë§ & ì €ì¥ í•¨ìˆ˜
def crawl_and_save_to_csv():
    ëª¨ë¸ëª… = []; ì—°ë¹„ = []; ì—°ë£Œíƒ€ì… = []; ì°¨ê¸‰ = []; ì™¸í˜• = []; ì—”ì§„ = []
    ê°€ê²© = []; ì´ë¯¸ì§€ = []; ì¶œë ¥ = []

    for i in range(7576, 4000, -1):
        try:
            url = f'https://www.carisyou.com/car/{i}/Spec'
            response = requests.get(url)
            time.sleep(0.1)
            response.raise_for_status()
            parser = BeautifulSoup(response.text, 'lxml')

            elements = parser.select('div.car_gallery > h4.title, div.car_info > div.info > dl > dd,\
                                     #carInfo > div:nth-child(5) > div > div.table_box_left > table > tbody > tr:nth-child(1) > td')
            elements2 = parser.select('div.car_info > h4 > span')
            elements3 = parser.select('#container > div:nth-child(3) > div > div.car_detail_top > div.car_detail > div.car_gallery > p > img')
            elements4 = parser.select('#carInfo > div:nth-child(4) > div > div.table_box_left > table > tbody > tr:nth-child(2) > td,\
                                      #carInfo > div:nth-child(4) > div > div.table_box_right > table > tbody > tr:nth-child(7) > td,\
                                      #carInfo > div:nth-child(4) > div > div.table_box_right > table > tbody > tr:nth-child(5) > td')

            if not (elements and elements2 and elements3 and elements4):
                st.warning(f"[{i}] ìš”ì†Œ ëˆ„ë½")
                continue

            if elements2[0].text == '-': continue
            ëª¨ë¸ëª….append(elements[0].text)
            ì—°ë¹„.append(elements[1].text.replace('\xa0', '').replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', ''))
            ì—°ë£Œíƒ€ì….append(elements[2].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', ''))
            ì°¨ê¸‰.append(elements[3].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', ''))
            ì™¸í˜•.append(elements[4].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', ''))
            ì—”ì§„.append(elements[5].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', ''))

            
            if len(elements2) == 3 or len(elements2) == 4:
                price = elements2[-2].text.strip().replace(',', '') + '{:04}'.format(elements2[-1].text.strip().replace(',', ''))
                ê°€ê²©.append(price)
            elif len(elements2) == 2:
                if len(elements2[0].text.strip()) <= 2:
                    price = elements2[0].text.strip().replace(',', '') + '{:04}'.format(elements2[-1].text.strip().replace(',', ''))
                    ê°€ê²©.append(price)
                else:
                    ê°€ê²©.append(elements2[1].text.strip().replace(',', ''))
            else:
                ê°€ê²©.append(elements2[0].text.strip().replace(',', ''))

            ì´ë¯¸ì§€.append(elements3[0].get('src'))

            horse_p = elements4[0].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', '')
            if horse_p.strip() == '-ë§ˆë ¥' and len(elements4) > 1: 
                ì¶œë ¥.append(elements4[-1].text.replace('\t', '').replace('\n', '').replace('\r', '').replace(' ', '')) 
            else: ì¶œë ¥.append(horse_p)

        except Exception as e:
            st.warning(f"[{i}] ì—ëŸ¬ ë°œìƒ: {e}")
            continue

    d = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
    file_path = f"{save_dir}/{d}.csv"

    result_df = pd.DataFrame({
        'ëª¨ë¸ëª…': ëª¨ë¸ëª…,
        'ì—°ë¹„': ì—°ë¹„,
        'ì—°ë£Œíƒ€ì…': ì—°ë£Œíƒ€ì…,
        'ì°¨ê¸‰': ì°¨ê¸‰,
        'ì™¸í˜•': ì™¸í˜•,
        'ì—”ì§„': ì—”ì§„,
        'ê°€ê²©': ê°€ê²©,
        'ì´ë¯¸ì§€': ì´ë¯¸ì§€,
        'ì¶œë ¥': ì¶œë ¥
    })

    result_df.to_csv(file_path, index=False)
    return file_path, result_df

# DB ì‚½ì… í•¨ìˆ˜
def insert_csv_to_db(file_path, df):
    conn = pymysql.connect(
        host='192.168.0.15',
        user='user5',
        password='9999',
        database='test_db',
        charset='utf8mb4'
    )
    cursor = conn.cursor()

    for idx, row in df.iterrows():
        sql = """
        INSERT INTO car_info (
            model, fuel_effic, fuel_type, car_level, outfit, engine_type,
            price, img_url, horse_power
        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        try:
            cursor.execute(sql, (
                row['ëª¨ë¸ëª…'],
                row['ì—°ë¹„'],
                row['ì—°ë£Œíƒ€ì…'],
                row['ì°¨ê¸‰'],
                row['ì™¸í˜•'],
                row['ì—”ì§„'],
                int(row['ê°€ê²©']) if pd.notna(row['ê°€ê²©']) and str(row['ê°€ê²©']).isdigit() else None,
                row['ì´ë¯¸ì§€'],
                row['ì¶œë ¥']
            ))
        except Exception as e:
            st.warning(f"[{idx}] DB ì‚½ì… ì‹¤íŒ¨ - ëª¨ë¸ëª…: {row.get('ëª¨ë¸ëª…', 'N/A')} / ì—ëŸ¬: {e}")
            continue

    conn.commit()
    cursor.close()
    conn.close()

# Streamlit UI
st.set_page_config(page_title="Carisyou í¬ë¡¤ë§ â†’ DB", layout="centered")
st.title("ğŸš— Carisyou í¬ë¡¤ë§ â†’ DB ì—…ë¡œë“œ")

if st.button("âœ… ë°ì´í„° ìˆ˜ì§‘ ë° DB ì €ì¥"):
    with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
        csv_path, df = crawl_and_save_to_csv()
        st.success(f"CSV ì €ì¥ ì™„ë£Œ âœ…\nğŸ“ ê²½ë¡œ: {csv_path}")
        insert_csv_to_db(csv_path, df)
        st.success("ğŸ‰ MySQL ì €ì¥ ì™„ë£Œ!")
